{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {\n",
    "    \"lr\": [1e-1,1e-2,1e-3,1e-4],\n",
    "    \"hidden_layers\": [[200, 100, 50], [200, 100], [200]],\n",
    "    \"activation_funcs\": [nn.ReLU(),nn.LeakyReLU(),nn.Sigmoid()],\n",
    "    \"batch_size\":64,\n",
    "    \"num_epoch\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "\n",
    "train_transform = T.Compose ([\n",
    "# can add additional transforms on images\n",
    "T.ToTensor(), # convert images to PyTorch tensors\n",
    "T.Grayscale(), # RGB to grayscale\n",
    "T.Normalize( mean =(0.5 ,) , std=(0.5 ,) ) # n or ma li za ti on\n",
    "# speeds up the convergence\n",
    "# and improves the accuracy\n",
    "])\n",
    "val_transform = test_transform = T.Compose([\n",
    "T.ToTensor() ,\n",
    "T.Grayscale() ,\n",
    "T.Normalize( mean =(0.5 ,) , std=(0.5 ,) )\n",
    "])\n",
    "\n",
    "train_set = CIFAR10 ( root =\"CIFAR10\", train =True ,transform = train_transform , download = True )\n",
    "test_set = CIFAR10 ( root =\"CIFAR10\", train =False ,transform = test_transform , download = True )\n",
    "train_set_length = int(0.8 * len(train_set))\n",
    "val_set_length = len(train_set) - train_set_length\n",
    "train_set, val_set = random_split(train_set, [train_set_length, val_set_length])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=HP[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=HP[\"batch_size\"])\n",
    "val_loader = DataLoader(val_set, batch_size=HP[\"batch_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, output_shape, hidden_layers,activation):\n",
    "        super().__init__()\n",
    "        layers = [32*32*1] + hidden_layers + [output_shape]\n",
    "        modules = []\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            modules.append(activation)\n",
    "        self.lin = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------training with---------------\n",
      "0.1\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): Sigmoid()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): Sigmoid()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): Sigmoid()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (5): Sigmoid()\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.1\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.01\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.001\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "ReLU()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n",
      "---------------training with---------------\n",
      "0.0001\n",
      "Sigmoid()\n",
      "MyModel(\n",
      "  (lin): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(HP[\"hidden_layers\"])):\n",
    "    for j in range(len(HP[\"lr\"])):\n",
    "        for k in range(len(HP[\"activation_funcs\"])):\n",
    "\n",
    "            model = MyModel(10, hidden_layers=(HP[\"hidden_layers\"][i]),activation=HP[\"activation_funcs\"][k]).to(device)\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=HP[\"lr\"][j])\n",
    "            \n",
    " \n",
    "            for epoch in tqdm(range(HP[\"num_epoch\"])):\n",
    "                # Training\n",
    "                model.train()\n",
    "                accum_train_loss = 0\n",
    "                for i, (imgs, labels) in enumerate(train_loader, start=1):\n",
    "                    tqdm()\n",
    "                    imgs, labels = imgs.to(device), labels.to(device)\n",
    "                    output = model(imgs)\n",
    "                    loss = loss_function(output, labels)\n",
    "\n",
    "                    # accumlate the loss\n",
    "                    accum_train_loss += loss.item()\n",
    "\n",
    "                    # backpropagation\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # Validation\n",
    "                model.eval()\n",
    "                accum_val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for j, (imgs, labels) in enumerate(val_loader, start=1):\n",
    "                        imgs, labels = imgs.to(device), labels.to(device)\n",
    "                        output = model(imgs)\n",
    "                        accum_val_loss += loss_function(output, labels).item()\n",
    "\n",
    "                # print statistics of the epoch\n",
    "                print(f'Epoch = {epoch} | Train Loss = {accum_train_loss / i:.4f}\\tVal Loss = {accum_val_loss / j:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epoch)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    accum_train_loss = 0\n",
    "    for i, (imgs, labels) in enumerate(train_loader, start=1):\n",
    "        tqdm()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        output = model(imgs)\n",
    "        loss = loss_function(output, labels)\n",
    "\n",
    "        # accumlate the loss\n",
    "        accum_train_loss += loss.item()\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    accum_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (imgs, labels) in enumerate(val_loader, start=1):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            output = model(imgs)\n",
    "            accum_val_loss += loss_function(output, labels).item()\n",
    "\n",
    "    # print statistics of the epoch\n",
    "    print(f'Epoch = {epoch} | Train Loss = {accum_train_loss / i:.4f}\\tVal Loss = {accum_val_loss / j:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"---------------training with---------------\")\n",
    "print(HP[\"lr\"][j])\n",
    "print(HP[\"activation_funcs\"][k])\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73cb587e981b46ef4cd8747ecb5a483b6f1d7dde7741ee2cacb92c485f9a68cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
