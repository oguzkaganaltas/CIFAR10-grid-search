{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fix the randomness\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {\n",
    "    \"lr\": [1e-1,1e-2,1e-3,1e-4],\n",
    "    \"neurons\": [1,2,3],\n",
    "    \"hidden_layers\": [[200, 100, 50], [200, 100], [200]],\n",
    "    \"activation_funcs\": [nn.ReLU(),nn.LeakyReLU(),nn.Sigmoid()],\n",
    "    \"batch_size\":32,\n",
    "    \"num_epoch\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "\n",
    "train_transform = T.Compose ([\n",
    "T.ToTensor(),\n",
    "T.Grayscale(),\n",
    "T.Normalize(mean =(0.5,), std=(0.5,))\n",
    "])\n",
    "val_transform = test_transform = T.Compose([\n",
    "T.ToTensor(),\n",
    "T.Grayscale(),\n",
    "T.Normalize(mean =(0.5,) , std=(0.5,))\n",
    "])\n",
    "\n",
    "train_set = CIFAR10 ( root =\"CIFAR10\", train =True ,transform = train_transform , download = True )\n",
    "test_set = CIFAR10 ( root =\"CIFAR10\", train =False ,transform = test_transform , download = True )\n",
    "train_set_length = int(0.8 * len(train_set))\n",
    "val_set_length = len(train_set) - train_set_length\n",
    "train_set, val_set = random_split(train_set, [train_set_length, val_set_length])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=HP[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=HP[\"batch_size\"])\n",
    "val_loader = DataLoader(val_set, batch_size=HP[\"batch_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, output_shape, hidden_layers,activation):\n",
    "        super().__init__()\n",
    "        layers = [32*32*1] + hidden_layers + [output_shape]\n",
    "        modules = []\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            modules.append(activation)\n",
    "        self.lin = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(m,i,j,k):\n",
    "    for epoch in tqdm(range(HP[\"num_epoch\"])):\n",
    "        # Training\n",
    "        model.train()\n",
    "        accum_train_loss = 0\n",
    "        for n, (imgs, labels) in enumerate(train_loader, start=1):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            output = model(imgs)\n",
    "            loss = loss_function(output, labels)\n",
    "\n",
    "            # accumlate the loss\n",
    "            accum_train_loss += loss.item()\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        accum_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, (imgs, labels) in enumerate(val_loader, start=1):\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                output = model(imgs)\n",
    "                accum_val_loss += loss_function(output, labels).item()\n",
    "        \n",
    "        # print statistics of the epoch\n",
    "        print(f'Epoch = {epoch} | Train Loss = {accum_train_loss / n:.4f}\\tVal Loss = {accum_val_loss / x:.4f}')\n",
    "\n",
    "    return [HP[\"neurons\"][m],HP[\"hidden_layers\"][i],HP[\"lr\"][j],HP[\"activation_funcs\"][k],accum_train_loss / n ,accum_val_loss / x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for m in range(len(HP[\"neurons\"])):\n",
    "    for i in range(len(HP[\"hidden_layers\"])):\n",
    "        for j in range(len(HP[\"lr\"])):\n",
    "            for k in range(len(HP[\"activation_funcs\"])):\n",
    "                \n",
    "                model = MyModel(10, hidden_layers=((np.array(HP[\"hidden_layers\"][i])*HP[\"neurons\"][m]).tolist()),activation=HP[\"activation_funcs\"][k]).to(device)\n",
    "                loss_function = nn.CrossEntropyLoss()\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=HP[\"lr\"][j])\n",
    "                a = fit(m,i,j,k)\n",
    "                print(a)\n",
    "                results.append(a)            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73cb587e981b46ef4cd8747ecb5a483b6f1d7dde7741ee2cacb92c485f9a68cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
